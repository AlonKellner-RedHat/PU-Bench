vpudra_softlabel:
  # Optimizer hyperparameters (same as VPUDRa-Fixed and VPU)
  optimizer: "adam"
  lr: 0.0003
  weight_decay: 0.0001

  # Training schedule
  batch_size: 256
  num_epochs: 40
  seed: 42

  # VPUDRa-SoftLabel specific
  mix_alpha: 0.3      # Beta distribution parameter for MixUp (same as VPU)
  epsilon: 1e-7       # Numerical stability in log operations

  # Note: Uses true prior from dataset (via BaseTrainer self.prior), NOT a config parameter
  # This variant differs from VPUDRa-Fixed only in the MixUp target formulation:
  #   - VPUDRa-Fixed: sam_target = λ * p(x) + (1-λ) * 1.0  (anchor assumption: p(positive)=1)
  #   - VPUDRa-SoftLabel: μ = λ * p(x) + (1-λ) * p(p_mix)  (NO anchor assumption)
  #
  # The soft label μ is used in Point Process loss: L(μ, p) = -μ log p + p
  # This is the natural extension of PUDRa's loss structure to soft labels.

  # Label scheme (standard PU convention)
  label_scheme:
    true_positive_label: 1
    true_negative_label: 0
    pu_labeled_label: 1
    pu_unlabeled_label: -1

  # Early stopping configuration
  checkpoint:
    enabled: true
    save_model: false
    monitor: "val_f1"      # Monitor validation F1 score
    mode: "max"            # Maximize F1
    early_stopping:
      enabled: true
      patience: 10         # Stop if no improvement for 10 epochs
      min_delta: 0.0001    # Minimum improvement threshold
